#!/usr/bin/env python3
"""
Evaluation Script for Diffusion Model Code Repairs

This script implements metrics to evaluate the quality of code repairs
generated by the diffusion model.
"""

import os
import torch
import subprocess
import tempfile
import difflib
import json
import numpy as np
from tqdm import tqdm
from tree_sitter import Language
import argparse
import logging

# Import from your existing codebase
from train_diffusion_model import (
    CodeDiffusionModel, 
    generate_repair,
    graph_to_code
)

# Setup logging
logging.basicConfig(
    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',
    datefmt='%m/%d/%Y %H:%M:%S',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

def load_model(model_path, node_dim=7, hidden_dim=128, num_timesteps=100, device="cuda"):
    """Load the trained diffusion model"""
    device = torch.device(device)
    checkpoint = torch.load(model_path, map_location=device)
    
    model = CodeDiffusionModel(
        node_dim=node_dim,
        hidden_dim=hidden_dim,
        num_timesteps=num_timesteps
    ).to(device)
    
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    return model, device

def check_syntax_validity(code):
    """Check if the code compiles (syntax validity)"""
    with tempfile.NamedTemporaryFile(suffix='.c') as temp:
        temp.write(code.encode('utf-8'))
        temp.flush()
        
        # Try to compile with gcc
        result = subprocess.run(
            ['gcc', '-fsyntax-only', temp.name],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        # Return 1 if compilation succeeded, 0 otherwise
        return 1 if result.returncode == 0 else 0

def check_vulnerability_removal(vulnerable_code, repaired_code):
    """Check if the vulnerability was removed using a static analyzer"""
    # This is a simplified example - in practice, you'd use a real vulnerability scanner
    # like Flawfinder, Cppcheck, or a more sophisticated tool
    
    # For demonstration, we'll check for common vulnerable functions
    vulnerable_patterns = [
        'strcpy(', 'sprintf(', 'gets(', 'scanf("%s"',
        'system(', 'exec(', 'popen('
    ]
    
    # Check if any vulnerable patterns were removed
    for pattern in vulnerable_patterns:
        if pattern in vulnerable_code and pattern not in repaired_code:
            return 1
    
    # If the vulnerable code doesn't contain any known patterns,
    # or if the repair didn't remove them, return 0
    return 0

def compute_semantic_similarity(reference_code, generated_code):
    """Compute semantic similarity between reference and generated code"""
    # This is a simplified example using text similarity
    # In practice, you might use more sophisticated code similarity metrics
    
    # Normalize whitespace and remove comments
    def normalize_code(code):
        lines = []
        for line in code.split('\n'):
            line = line.split('//')[0].strip()  # Remove comments
            if line:
                lines.append(line)
        return ' '.join(lines)
    
    ref_normalized = normalize_code(reference_code)
    gen_normalized = normalize_code(generated_code)
    
    # Use difflib's SequenceMatcher to compute similarity
    matcher = difflib.SequenceMatcher(None, ref_normalized, gen_normalized)
    return matcher.ratio()

def compute_edit_distance(original_code, repaired_code):
    """Compute the edit distance (number of changes) between original and repaired code"""
    # Split into lines and compute line-based diff
    original_lines = original_code.splitlines()
    repaired_lines = repaired_code.splitlines()
    
    # Use difflib to compute the differences
    diff = list(difflib.unified_diff(original_lines, repaired_lines, n=0))
    
    # Count the number of lines that were added or removed
    edit_count = sum(1 for line in diff if line.startswith('+') or line.startswith('-'))
    
    # Normalize by the length of the original code
    return edit_count / max(len(original_lines), 1)

def run_flawfinder(code):
    """Run flawfinder (a C/C++ static analyzer) on code and return the number of vulnerabilities"""
    with tempfile.NamedTemporaryFile(suffix='.c') as temp:
        temp.write(code.encode('utf-8'))
        temp.flush()
        
        try:
            # Run flawfinder (if installed)
            result = subprocess.run(
                ['flawfinder', '--quiet', '--minlevel=3', temp.name],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            # Count the number of vulnerabilities found
            output = result.stdout
            vuln_count = output.count('(CWE')
            return vuln_count
        except FileNotFoundError:
            logger.warning("Flawfinder not installed. Skipping vulnerability scan.")
            return -1

def load_test_examples():
    """Load test examples with vulnerable code and reference repairs"""
    return [
        # Buffer overflow example
        (
            """void copy_user_data(char *user_input) {
                char buffer[10];
                strcpy(buffer, user_input);  // Vulnerable: buffer overflow
                printf("Buffer contains: %s\\n", buffer);
            }""",
            
            """void copy_user_data(char *user_input) {
                char buffer[10];
                strncpy(buffer, user_input, sizeof(buffer) - 1);  // Fixed: use strncpy with size limit
                buffer[sizeof(buffer) - 1] = '\\0';  // Ensure null termination
                printf("Buffer contains: %s\\n", buffer);
            }"""
        ),
        
        # SQL injection example
        (
            """void query_user(char *user_id) {
                char query[100];
                sprintf(query, "SELECT * FROM users WHERE id='%s'", user_id);  // Vulnerable: SQL injection
                execute_query(query);
            }""",
            
            """void query_user(char *user_id) {
                char query[100];
                // Fixed: use prepared statements or proper escaping
                char *escaped_id = escape_sql_string(user_id);
                snprintf(query, sizeof(query), "SELECT * FROM users WHERE id='%s'", escaped_id);
                free(escaped_id);
                execute_query(query);
            }"""
        ),
        
        # Format string vulnerability
        (
            """void log_message(char *user_message) {
                printf(user_message);  // Vulnerable: format string vulnerability
            }""",
            
            """void log_message(char *user_message) {
                printf("%s", user_message);  // Fixed: use %s format specifier
            }"""
        ),
        
        # Integer overflow
        (
            """void allocate_buffer(size_t size) {
                char *buf = malloc(size);  // Vulnerable: no check for integer overflow
                // use buf...
                free(buf);
            }""",
            
            """void allocate_buffer(size_t size) {
                if (size == 0 || size > MAX_ALLOCATION) {  // Fixed: check for overflow
                    return;
                }
                char *buf = malloc(size);
                if (buf == NULL) {
                    return;
                }
                // use buf...
                free(buf);
            }"""
        ),
        
        # Command injection
        (
            """void execute_command(char *user_command) {
                char cmd[256];
                sprintf(cmd, "ls %s", user_command);  // Vulnerable: command injection
                system(cmd);
            }""",
            
            """void execute_command(char *user_command) {
                // Fixed: validate input or use safer alternatives
                if (!is_valid_filename(user_command)) {
                    printf("Invalid command\\n");
                    return;
                }
                char cmd[256];
                snprintf(cmd, sizeof(cmd), "ls %s", user_command);
                system(cmd);
            }"""
        )
    ]

def evaluate_repairs(model, test_examples, language, device, num_timesteps=100):
    """Evaluate model on test examples with multiple metrics"""
    results = {
        'syntax_validity': [],
        'vulnerability_removal': [],
        'semantic_similarity': [],
        'edit_distance': [],
        'vulnerability_count_before': [],
        'vulnerability_count_after': []
    }
    
    for i, (vulnerable_code, reference_repair) in enumerate(tqdm(test_examples, desc="Evaluating repairs")):
        logger.info(f"\nEvaluating example {i+1}/{len(test_examples)}")
        
        # Generate repair
        generated_repair = generate_repair(model, vulnerable_code, language, device, num_timesteps)
        
        # Evaluate metrics
        syntax_valid = check_syntax_validity(generated_repair)
        vuln_removed = check_vulnerability_removal(vulnerable_code, generated_repair)
        semantic_sim = compute_semantic_similarity(reference_repair, generated_repair)
        edit_dist = compute_edit_distance(vulnerable_code, generated_repair)
        
        # Run vulnerability scanner if available
        vuln_count_before = run_flawfinder(vulnerable_code)
        vuln_count_after = run_flawfinder(generated_repair)
        
        # Store results
        results['syntax_validity'].append(syntax_valid)
        results['vulnerability_removal'].append(vuln_removed)
        results['semantic_similarity'].append(semantic_sim)
        results['edit_distance'].append(edit_dist)
        results['vulnerability_count_before'].append(vuln_count_before)
        results['vulnerability_count_after'].append(vuln_count_after)
        
        # Print example results
        logger.info(f"Original (vulnerable):\n{vulnerable_code}\n")
        logger.info(f"Generated repair:\n{generated_repair}\n")
        logger.info(f"Reference repair:\n{reference_repair}\n")
        logger.info(f"Metrics for this example:")
        logger.info(f"  Syntax validity: {syntax_valid}")
        logger.info(f"  Vulnerability removal: {vuln_removed}")
        logger.info(f"  Semantic similarity: {semantic_sim:.2f}")
        logger.info(f"  Edit distance: {edit_dist:.2f}")
        if vuln_count_before >= 0 and vuln_count_after >= 0:
            logger.info(f"  Vulnerabilities before: {vuln_count_before}")
            logger.info(f"  Vulnerabilities after: {vuln_count_after}")
    
    # Compute averages
    avg_results = {
        'syntax_validity': sum(results['syntax_validity']) / len(results['syntax_validity']),
        'vulnerability_removal': sum(results['vulnerability_removal']) / len(results['vulnerability_removal']),
        'semantic_similarity': sum(results['semantic_similarity']) / len(results['semantic_similarity']),
        'edit_distance': sum(results['edit_distance']) / len(results['edit_distance'])
    }
    
    # Only include vulnerability counts if flawfinder was available
    if results['vulnerability_count_before'][0] >= 0:
        vuln_reduction = []
        for before, after in zip(results['vulnerability_count_before'], results['vulnerability_count_after']):
            if before > 0:
                reduction = (before - after) / before
                vuln_reduction.append(reduction)
            else:
                vuln_reduction.append(1.0 if after == 0 else 0.0)
        
        avg_results['vulnerability_reduction'] = sum(vuln_reduction) / len(vuln_reduction)
    
    logger.info("\nOverall Results:")
    logger.info(f"Syntax Validity: {avg_results['syntax_validity']:.2f}")
    logger.info(f"Vulnerability Removal Rate: {avg_results['vulnerability_removal']:.2f}")
    logger.info(f"Semantic Similarity: {avg_results['semantic_similarity']:.2f}")
    logger.info(f"Average Edit Distance: {avg_results['edit_distance']:.2f}")
    
    if 'vulnerability_reduction' in avg_results:
        logger.info(f"Vulnerability Reduction: {avg_results['vulnerability_reduction']:.2f}")
    
    return results, avg_results

def main():
    parser = argparse.ArgumentParser(description="Evaluate diffusion model code repairs")
    parser.add_argument("--model_path", type=str, default="./diffusion_checkpoints/best_model.pt",
                        help="Path to the trained model checkpoint")
    parser.add_argument("--node_dim", type=int, default=7,
                        help="Dimension of node features")
    parser.add_argument("--hidden_dim", type=int, default=128,
                        help="Hidden dimension size")
    parser.add_argument("--num_timesteps", type=int, default=100,
                        help="Number of diffusion timesteps")
    parser.add_argument("--device", type=str, default="cuda" if torch.cuda.is_available() else "cpu",
                        help="Device to run evaluation on")
    parser.add_argument("--output_file", type=str, default="evaluation_results.json",
                        help="File to save evaluation results")
    
    args = parser.parse_args()
    
    # Load the model
    logger.info(f"Loading model from {args.model_path}")
    model, device = load_model(
        args.model_path,
        node_dim=args.node_dim,
        hidden_dim=args.hidden_dim,
        num_timesteps=args.num_timesteps,
        device=args.device
    )
    
    # Load language for parsing
    try:
        language = Language('/home/hohoanghvy/tree-sitter-container/build/my-languages.so', 'c')
        logger.info("Successfully loaded C language")
    except Exception as e:
        logger.error(f"Failed to load C language: {e}")
        logger.info("Trying alternative language paths...")
        
        # Try alternative paths
        for lang_path in [
            '/home/hohoanghvy/PycharmProjects/DefectDetection/build/my-languages.so',
            '/home/hohoanghvy/PycharmProjects/GNN-CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/parser/my-languages.so',
            os.path.expanduser('~/tree-sitter-languages/languages.so')
        ]:
            if os.path.exists(lang_path):
                try:
                    language = Language(lang_path, 'c')
                    logger.info(f"Successfully loaded C language from {lang_path}")
                    break
                except Exception:
                    continue
        else:
            logger.error("Could not load C language from any known path")
            return
    
    # Load test examples
    test_examples = load_test_examples()
    logger.info(f"Loaded {len(test_examples)} test examples")
    
    # Evaluate the model
    results, avg_results = evaluate_repairs(
        model, 
        test_examples, 
        language, 
        device, 
        num_timesteps=args.num_timesteps
    )
    
    # Save results
    output = {
        'average_results': avg_results,
        'individual_results': results
    }
    
    with open(args.output_file, 'w') as f:
        json.dump(output, f, indent=2)
    
    logger.info(f"Saved evaluation results to {args.output_file}")
    
    # Suggest next steps
    logger.info("\nNext steps:")
    logger.info("1. Visualize these results with: python visualize_results.py")
    logger.info("2. Try different model parameters or timesteps")
    logger.info("3. Add more test examples for a more comprehensive evaluation")

if __name__ == "__main__":
    main()
